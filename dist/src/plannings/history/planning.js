"use strict";
/**
 * @fileoverview
 * este arquivo √© o mais complexo do sistema, possui varias funcionalidades.
 * 1 - Sele√ß√£o e execu√ß√£o de ferramentas
 * 2- gera√ß√£o de r4esposta final.
 */
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.generateResponse = exports.runToolSelectorAgent = exports.generateResponseOpenAI = void 0;
const traceable_1 = require("langsmith/traceable");
const messages_1 = require("@langchain/core/messages");
const config_1 = require("../../config");
const memory_1 = require("../../memory");
const tools_1 = require("../../tools/history/tools");
// essa fun√ß√£o gera a resposta da pergunta
exports.generateResponseOpenAI = (0, traceable_1.traceable)(function OpenAiChatCompleiton(messages_2) {
    return __awaiter(this, arguments, void 0, function* (messages, // historico de mensagem
    modelType = "advanced", // modelos pre definidos (com a inten√ß√£o de diminuir a lat√™ncia)
    onChunk // streaming
    ) {
        var _a, e_1, _b, _c;
        try {
            /**
             * Indentifica o papel da mensagem
             * Converte as mensagens em formato langchain
             * Qualquer coisa fora do padr√£o √© mensagen di tipo HumanMessage, para garantir que nada quebre
             */
            const langchainMessages = messages.map((msg) => {
                if (msg.role === "system")
                    return new messages_1.SystemMessage(msg.content);
                if (msg.role === "user")
                    return new messages_1.HumanMessage(msg.content);
                if (msg.role === "assistant")
                    return new messages_1.AIMessage(msg.content);
                return new messages_1.HumanMessage(msg.content);
            });
            // define o modelo
            let selectedModel;
            if (modelType === "advanced") {
                selectedModel = config_1.advancedModel;
            }
            else if (modelType === "balanced") {
                selectedModel = config_1.balancedModel;
            }
            else {
                selectedModel = config_1.fastModel;
            }
            // caso seja o streaming esteja ativado, vai fazer o streaming
            if (onChunk) {
                const stream = yield selectedModel.stream(langchainMessages);
                let fullResponse = "";
                try {
                    for (var _d = true, stream_1 = __asyncValues(stream), stream_1_1; stream_1_1 = yield stream_1.next(), _a = stream_1_1.done, !_a; _d = true) {
                        _c = stream_1_1.value;
                        _d = false;
                        const chunk = _c;
                        const content = String(chunk.content || "");
                        if (content) {
                            onChunk(content);
                        }
                        fullResponse += content;
                    }
                }
                catch (e_1_1) { e_1 = { error: e_1_1 }; }
                finally {
                    try {
                        if (!_d && !_a && (_b = stream_1.return)) yield _b.call(stream_1);
                    }
                    finally { if (e_1) throw e_1.error; }
                }
                return fullResponse;
            }
            else {
                // invoka a resposta do llm
                const response = yield selectedModel.invoke(langchainMessages);
                return String(response.content);
            }
        }
        catch (error) {
            console.error("Error in OpenAiChatCompletion:", error);
            throw error;
        }
    });
}, {
    name: "Generate Responde OpenAI",
    run_type: "llm",
    metadata: {
        provider: "OpenAI"
    }
});
// essa fun√ß√£o √© um agente que pega o input do usu√°rio e com base nele determina qual a tool mais adequada.
exports.runToolSelectorAgent = (0, traceable_1.traceable)(function toolSelector(userInput_1) {
    return __awaiter(this, arguments, void 0, function* (userInput, // input do usuario
    sessionHistory = [] // historico da conversa
    ) {
        // prompt de instru√ß√£o do sistema.
        const systemPrompt = `
            Voc√™ √© um roteador de tarefas inteligente. Analise a INTEN√á√ÉO da pergunta, n√£o apenas as palavras exatas.

            ### Ferramentas Dispon√≠veis

                1. **specific_query_tool**: Busca informa√ß√µes espec√≠ficas sobre UMA entidade.
        
                    **Quando usar:**
                    - Pergunta menciona nome espec√≠fico de empresa, representante, organiza√ß√£o, etc.
                    - Usu√°rio quer saber sobre UM item espec√≠fico
                    - Funciona para QUALQUER propriedade: documento, plano, tipo, revenue, etc.
        
                    **Exemplos (n√£o limitado a estes):**
                        - "Qual o documento da iFood?"
                        - "Me fale o plano da SEM PARAR"
                        - "Qual o tipo da CREDIFY?"
                        - "Qual a organiza√ß√£o do SEGUNDO CART√ìRIO?"
                        - "Qual o revenue da iFood?"
        
                    **Varia√ß√µes aceitas:**
                        - "iFood tem qual documento?" ‚Üí ‚úÖ Mesma inten√ß√£o
                        - "Me mostre o plano da SEM PARAR" ‚Üí ‚úÖ Mesma inten√ß√£o
        
                    **Retorno:**
                    {"tool": "specific_query_tool", "input": {"query": "...", "filters": {}}}

                2. **aggregate_tool**: Agrega dados por QUALQUER campo.
        
                    **Quando usar:**
                        - Pergunta pede compara√ß√£o, ranking ou total de M√öLTIPLOS itens
                        - Usu√°rio quer ver dados agrupados
                        - Funciona para: representative, company, organization, revenue, plan, company_type, etc.
        
                    **Exemplos (n√£o limitado a estes):**
                        - "Desempenho por representante" ‚Üí groupBy: "representative"
                        - "Desempenho por empresa" ‚Üí groupBy: "company"
                        - "Agregue por organiza√ß√£o" ‚Üí groupBy: "organization"
                        - "Total por revenue" ‚Üí groupBy: "revenue"
                        - "Agrupe por plano" ‚Üí groupBy: "plan"
                        - "Empresas por tipo" ‚Üí groupBy: "company_type"

                        **Varia√ß√µes aceitas:**
                        - "Mostre cada representante" ‚Üí ‚úÖ groupBy: "representative"
                        - "Ranking de vendedores" ‚Üí ‚úÖ groupBy: "representative"
                        - "Compare as empresas" ‚Üí ‚úÖ groupBy: "company"
        
                    **Retorno:**
                    {"tool": "aggregate_tool", "input": {"query": "...", "filters": {}, "groupBy": "representative"}}
        
                    **‚ö†Ô∏è IMPORTANTE:** Voc√™ DEVE especificar o campo "groupBy" no input!

                3. **hybrid_search_tool**: Busca h√≠brida (fallback).
        
                    **Quando usar:**
                    - Pergunta √© amb√≠gua, complexa ou n√£o se encaixa claramente nas outras tools
                    - Voc√™ n√£o tem certeza qual tool usar
        
                    **Exemplos:**
                    - "Me explique como funciona..."
                    - "An√°lise detalhada de..."
                    - "Me fale sobre esses dados"
        
                    **Retorno:**
                    {"tool": "hybrid_search_tool", "input": {"query": "...", "filters": {}}}

                4. **none**: APENAS para cumprimentos e agradecimentos.
        
                    **Quando usar:**
                    - "oi", "ol√°", "bom dia"
                    - "obrigado", "valeu", "at√© logo"
        
                    **Retorno:**
                    {"tool": "none", "input": "..."}

            ### ‚ö†Ô∏è REGRAS CR√çTICAS:
                1. **Analise a INTEN√á√ÉO**, n√£o as palavras exatas
                2. **Os exemplos s√£o ilustrativos**, n√£o limitantes
                3. **Para agrega√ß√£o, SEMPRE especifique "groupBy"**
                4. **SE VOC√ä N√ÉO TEM CERTEZA** qual tool usar, escolha **hybrid_search_tool**
                5. **Formato JSON:** Retorne APENAS o JSON da ferramenta

            ### Exemplos Completos

            **Exemplo 1: Espec√≠fica**
                Hist√≥rico: []
                Usu√°rio: "Qual o documento da iFood?"
                Retorno:
                {"tool": "specific_query_tool", "input": {"query": "documento da iFood", "filters": {}}}

            **Exemplo 2: Agrega√ß√£o por Representante**
                Hist√≥rico: []
                Usu√°rio: "desempenho por representante"
                Retorno:
                {"tool": "aggregate_tool", "input": {"query": "desempenho de todos os representantes", "filters": {}, "groupBy": "representative"}}

            **Exemplo 3: Agrega√ß√£o por Plano**
                Hist√≥rico: []
                Usu√°rio: "agrupe por plano"
                Retorno:
                {"tool": "aggregate_tool", "input": {"query": "dados agrupados por plano", "filters": {}, "groupBy": "plan"}}

            **Exemplo 4: Agrega√ß√£o por Tipo de Empresa**
                Hist√≥rico: []
                Usu√°rio: "compare empresas master e unique"
                Retorno:
                {"tool": "aggregate_tool", "input": {"query": "compara√ß√£o entre tipos de empresa", "filters": {}, "groupBy": "company_type"}}

            **Exemplo 5: Amb√≠gua (Fallback)**
                Hist√≥rico: []
                Usu√°rio: "me explique como funciona"
                Retorno:
                {"tool": "hybrid_search_tool", "input": {"query": "explica√ß√£o sobre funcionamento", "filters": {}}}

            **Exemplo 6: Cumprimento**
                Hist√≥rico: [ ... ]
                Usu√°rio: "muito obrigado"
                Retorno:
                {"tool": "none", "input": "muito obrigado"}

    `.trim();
        // monta o hist√≥rico completo da conversa que sera enviada ao sistema.
        const messages = [
            { role: "system", content: systemPrompt },
            ...sessionHistory,
            { role: "user", content: userInput }
        ];
        try {
            // envia as mensagens para o llm e retorna a resposta
            const response = yield (0, exports.generateResponseOpenAI)(messages, "balanced");
            let toolCall;
            try {
                // converte a resposta para json
                toolCall = JSON.parse(response);
            }
            catch (parseError) {
                console.warn("‚ö†Ô∏è Erro ao parsear JSON. Usando fallback...");
                // caso haja alguma falha utiliza a ferramenta hybrid (generica)
                return {
                    tool: "hybrid_search_tool",
                    input: { query: userInput, filters: {} }
                };
            }
            // ferramentas validas
            const validTools = [
                "specific_query_tool",
                "aggregate_tool",
                "hybrid_search_tool",
                "none"
            ];
            if (!toolCall || !toolCall.tool || !validTools.includes(toolCall.tool)) {
                console.warn("‚ö†Ô∏è Tool inv√°lida. Usando fallback.");
                return {
                    tool: "hybrid_search_tool",
                    input: { query: userInput, filters: {} }
                };
            }
            if (!toolCall.input) {
                toolCall.input = { query: userInput, filters: {} };
            }
            if (toolCall.tool === "aggregate_tool" && !toolCall.input.groupBy) {
                toolCall.input.groupBy = "company";
            }
            console.log("‚úÖ Tool selecionada:", toolCall.tool);
            return {
                tool: toolCall.tool,
                input: toolCall.input
            };
        }
        catch (error) {
            console.error("‚ùå Erro no toolSelector:", error);
            return {
                tool: "hybrid_search_tool",
                input: { query: userInput, filters: {} }
            };
        }
    });
}, {
    name: "Tool Selector",
    run_type: "chain",
    metadata: {
        purpose: "Route user query to appropriate tool",
        model: "gpt-4o"
    }
});
const getLlmResponse = (0, traceable_1.traceable)(function getLlmResponse(messages_2, systemMessageContent_1) {
    return __awaiter(this, arguments, void 0, function* (messages, systemMessageContent, modelType = "advanced", onChunk) {
        const fullMessages = [
            { role: "system", content: systemMessageContent },
            ...messages
        ];
        const response = yield (0, exports.generateResponseOpenAI)(fullMessages, modelType, onChunk);
        return response;
    });
}, {
    name: "Get LLM Response",
    run_type: "chain",
    metadata: {
        purpose: "Generate final response with system prompt"
    }
});
/**
 * Fun√ß√£o principal que orquestra todo o processo. Ela √© respons√°vel por:
 */
exports.generateResponse = (0, traceable_1.traceable)(function generateResponse(sessionId, // sess√£o do chat do usuario
userInput, // pergunta do usuario
onChunk // streaming
) {
    return __awaiter(this, void 0, void 0, function* () {
        // armazena a pergunta do usu√°iro no hist√≥rico de se√ß√£o.
        yield (0, memory_1.storeChatMessage)(sessionId, "user", userInput);
        // recupera todo o hist√≥rico da conversa, para entender o contexto
        const sessionHistory = yield (0, memory_1.retrieverSessionHistory)(sessionId);
        const llmInput = [...sessionHistory];
        // retorno da fun√ß√£o que seleciona a ferramenta
        const { tool, input: toolInput } = yield (0, exports.runToolSelectorAgent)(userInput, sessionHistory);
        console.log("üîß Tool selecionada:", tool);
        let response;
        if (tool === "specific_query_tool") {
            console.log("üîç Executando specific_query_tool...");
            const finalFilters = { "month": sessionId };
            const finalToolInput = {
                query: toolInput.query || userInput,
                filters: finalFilters
            };
            const contextResults = yield (0, tools_1.specificQueryTool)(finalToolInput);
            const context = contextResults
                .map((doc) => { var _a; return ((_a = doc.document) === null || _a === void 0 ? void 0 : _a.pageContent) || JSON.stringify(doc); })
                .join('\n---\n');
            const systemMessageContent = `
Voc√™ √© um analista financeiro experiente. Responda usando o contexto fornecido.

**FORMATA√á√ÉO MONET√ÅRIA:**
- Os valores J√Å EST√ÉO EM REAIS (n√£o precisa converter)
- Campos como "totalValueInReais", "totalValueWithDiscountInReais" j√° est√£o prontos
- Use o padr√£o brasileiro: ponto (.) para separador de milhares, v√≠rgula (,) para decimais
- Exemplo: 11893.2337 ‚Üí R$ 11.893,2337
- Exemplo: 316852.5000 ‚Üí R$ 316.852,5000
- SEMPRE mostre exatamente 4 casas decimais ap√≥s a v√≠rgula
- NUNCA use v√≠rgula para separador de milhares

### üß© POL√çTICA DE FORMATA√á√ÉO DE RESPOSTAS (OBRIGAT√ìRIA)

Todas as respostas devem ser formatadas em **Markdown**, SEM EXCE√á√ÉO.

**Regras de Formata√ß√£o:**
1. **T√≠tulos:** Use \`##\` para t√≠tulos principais e \`###\` para subt√≠tulos.
2. **Negrito:** Use \`**texto**\` para destacar partes importantes.
3. **Tabelas:** Sempre que houver compara√ß√£o, agrega√ß√£o ou m√∫ltiplos itens (empresas, representantes, meses, etc.), use tabelas Markdown no formato:

   | Campo | Valor |
   |--------|--------|
   | Exemplo | R$ 1.234,56 |

4. **C√≥digo Inline:** Use crases \`texto\` para IDs, nomes t√©cnicos, ou campos JSON.
5. **Separadores:** Use \`---\` para separar blocos de informa√ß√£o.
6. **Listas:** Use listas numeradas ou com marcadores para explicar passos, m√©tricas ou observa√ß√µes.
7. **Emojis (opcional):** Pode usar √≠cones (üìä, üí∞, ‚öôÔ∏è) para dar contexto visual.
8. **Proibido:** N√£o retornar texto puro sem Markdown.
- Seja conciso mas informativo


Contexto:
${context}`.trim();
            response = yield getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        else if (tool === "aggregate_tool") {
            console.log("üìä Executando aggregate_tool...");
            const finalFilters = { "month": sessionId };
            const finalToolInput = {
                query: toolInput.query || userInput,
                filters: finalFilters,
                groupBy: toolInput.groupBy || "company"
            };
            const contextResults = yield (0, tools_1.aggregateTool)(finalToolInput);
            const contextData = JSON.parse(contextResults[0].document.pageContent);
            const context = JSON.stringify(contextData, null, 2);
            const systemMessageContent = `
Voc√™ √© um analista financeiro experiente. Os dados fornecidos J√Å EST√ÉO AGREGADOS.
N√ÉO precisa somar ou agrupar novamente! Apenas formate e analise.

**FORMATA√á√ÉO MONET√ÅRIA:**
- Os valores J√Å EST√ÉO EM REAIS (n√£o precisa converter)
- Campos como "totalValueInReais", "totalValueWithDiscountInReais" j√° est√£o prontos
- Use o padr√£o brasileiro: ponto (.) para separador de milhares, v√≠rgula (,) para decimais
- Exemplo: 11893.2337 ‚Üí R$ 11.893,2337
- Exemplo: 316852.5000 ‚Üí R$ 316.852,5000
- SEMPRE mostre exatamente 4 casas decimais ap√≥s a v√≠rgula
- NUNCA use v√≠rgula para separador de milhares

### üß© POL√çTICA DE FORMATA√á√ÉO DE RESPOSTAS (OBRIGAT√ìRIA)

Todas as respostas devem ser formatadas em **Markdown**, SEM EXCE√á√ÉO.

**Regras de Formata√ß√£o:**
1. **T√≠tulos:** Use \`##\` para t√≠tulos principais e \`###\` para subt√≠tulos.
2. **Negrito:** Use \`**texto**\` para destacar partes importantes.
3. **Tabelas:** Sempre que houver compara√ß√£o, agrega√ß√£o ou m√∫ltiplos itens (empresas, representantes, meses, etc.), use tabelas Markdown no formato:

   | Campo | Valor |
   |--------|--------|
   | Exemplo | R$ 1.234,56 |

4. **C√≥digo Inline:** Use crases \`texto\` para IDs, nomes t√©cnicos, ou campos JSON.
5. **Separadores:** Use \`---\` para separar blocos de informa√ß√£o.
6. **Listas:** Use listas numeradas ou com marcadores para explicar passos, m√©tricas ou observa√ß√µes.
7. **Emojis (opcional):** Pode usar √≠cones (üìä, üí∞, ‚öôÔ∏è) para dar contexto visual.
8. **Proibido:** N√£o retornar texto puro sem Markdown.
- Seja conciso mas informativo

Contexto (j√° agregado por ${toolInput.groupBy}):
${context}`.trim();
            response = yield getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        else if (tool === "hybrid_search_tool") {
            console.log("üîÄ Executando hybrid_search_tool...");
            const finalFilters = { "month": sessionId };
            const finalToolInput = {
                query: toolInput.query || userInput,
                filters: finalFilters
            };
            const contextResults = yield (0, tools_1.hybridSearchTool)(finalToolInput);
            const context = contextResults
                .map((doc) => { var _a; return ((_a = doc.document) === null || _a === void 0 ? void 0 : _a.pageContent) || JSON.stringify(doc); })
                .join('\n---\n');
            const systemMessageContent = `
Voc√™ √© um analista financeiro experiente. Fa√ßa uma an√°lise abrangente e detalhada.

**FORMATA√á√ÉO MONET√ÅRIA:**
- Os valores J√Å EST√ÉO EM REAIS (n√£o precisa converter)
- Campos como "totalValueInReais", "totalValueWithDiscountInReais" j√° est√£o prontos
- Use o padr√£o brasileiro: ponto (.) para separador de milhares, v√≠rgula (,) para decimais
- Exemplo: 11893.2337 ‚Üí R$ 11.893,2337
- Exemplo: 316852.5000 ‚Üí R$ 316.852,5000
- SEMPRE mostre exatamente 4 casas decimais ap√≥s a v√≠rgula
- NUNCA use v√≠rgula para separador de milhares

### üß© POL√çTICA DE FORMATA√á√ÉO DE RESPOSTAS (OBRIGAT√ìRIA)

Todas as respostas devem ser formatadas em **Markdown**, SEM EXCE√á√ÉO.

**Regras de Formata√ß√£o:**
1. **T√≠tulos:** Use \`##\` para t√≠tulos principais e \`###\` para subt√≠tulos.
2. **Negrito:** Use \`**texto**\` para destacar partes importantes.
3. **Tabelas:** Sempre que houver compara√ß√£o, agrega√ß√£o ou m√∫ltiplos itens (empresas, representantes, meses, etc.), use tabelas Markdown no formato:

   | Campo | Valor |
   |--------|--------|
   | Exemplo | R$ 1.234,56 |

4. **C√≥digo Inline:** Use crases \`texto\` para IDs, nomes t√©cnicos, ou campos JSON.
5. **Separadores:** Use \`---\` para separar blocos de informa√ß√£o.
6. **Listas:** Use listas numeradas ou com marcadores para explicar passos, m√©tricas ou observa√ß√µes.
7. **Emojis (opcional):** Pode usar √≠cones (üìä, üí∞, ‚öôÔ∏è) para dar contexto visual.
8. **Proibido:** N√£o retornar texto puro sem Markdown.
- Seja direto mas completo

Contexto:
${context}`.trim();
            response = yield getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        else if (tool === "calculator_tool") {
            console.log("üßÆ Executando calculator_tool...");
            response = (0, tools_1.calculatorTool)(toolInput);
            if (onChunk) {
                onChunk(response);
            }
        }
        else {
            console.log("üí¨ Nenhuma tool necess√°ria (cumprimento)");
            const systemMessageContent = `
                Voc√™ √© um assistente prestativo. Seja cordial.
                Use Markdown se necess√°rio.
            `.trim();
            response = yield getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        yield (0, memory_1.storeChatMessage)(sessionId, "system", response);
        return response;
    });
}, {
    name: "Generate Response - novo",
    run_type: "chain",
    metadata: {
        purpose: "Main orchestration with optimized model selection and streaming"
    }
});
