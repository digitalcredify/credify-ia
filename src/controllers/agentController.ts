/**
 * @fileoverview 
 * recebe a requisi√ß√£o, valida os dados de entrada, decide se √© com ou sem streaming e chama o agentService
 * oq √© streaming?: envia a resposta em chunks (peda√ßos de texto), igual ao chatGPT
 */

import { Request, Response } from 'express';
import agentService from '../service/agentService';
import { ENABLE_STREAMING } from '../config';

export const agentController = async (req: Request, res: Response) => {
    try {
        const { pergunta, jsonData, targetMonth } = req.body;

        if (!pergunta || !jsonData || !targetMonth) {
            return res.status(400).json({
                error: "Campos obrigat√≥rios: pergunta, jsonData, targetMonth"
            });
        }

        console.log(`üìù Pergunta recebida: "${pergunta}"`);
        console.log(`üìÖ M√™s alvo: ${targetMonth}`);
        console.log(`üîÑ Streaming: ${ENABLE_STREAMING ? 'HABILITADO' : 'DESABILITADO'}`);


        // fluxo  com streaming.
        if (ENABLE_STREAMING) {

            /**
             * configuran√ß√£o de cabecalhos HTTP para um conex√£o Server-sant Events(SSE)
             * SSE: mant√©m a conex√£o aberta para que o servidor possa enviar m√∫ltipos eventos.
             */
            res.setHeader('Content-Type', 'text/event-stream');
            res.setHeader('Cache-Control', 'no-cache');
            res.setHeader('Connection', 'keep-alive');
            res.setHeader('Access-Control-Allow-Origin', '*');
            
            // envia o cabe√ßalho IMEDIATAMENTE para o cliente.
            res.flushHeaders();

            let fullResponse = "";

            // callBack. ser√° chamada pelo agentService tpda vez que o llm gerar um novo chunk.
            const onChunk = (chunk: string) => {

                fullResponse += chunk; // adiciona um novo peda√ßo peda√ßo a resposta final.

                const sseMessage = `data: ${JSON.stringify({ fullResponse })}\n\n`; // formata para o padr√£o SSE j√° convertido em JSON.

                res.write(sseMessage); // envia o evento SSE parcial para o cliente sem finalizar a conex√£o, permitindo transmitir dados em tempo real.
            };

            try {
                await agentService(pergunta, jsonData, targetMonth, onChunk); 

                res.write(`data: ${JSON.stringify({ done: true, fullResponse })}\n\n`); // avisa para o cliente que o streaming acabou.
                res.end(); // fecha a conex√£o

                console.log(`‚úÖ Resposta enviada com sucesso (${fullResponse.length} caracteres)`);

            } catch (error) {
                console.error("‚ùå Erro ao gerar resposta:", error);
                
                const errorMessage = error instanceof Error ? error.message : "Erro desconhecido";
                res.write(`data: ${JSON.stringify({ error: errorMessage })}\n\n`);
                res.end();
            }
        } 
        else { 
            
            // fluxo sem streaming
            try {
                const response = await agentService(pergunta, jsonData, targetMonth); // chama o agentService sem o chunk

                // envia a resposta para o cliente
                res.status(200).json({
                    success: true,
                    response: response
                });


            } catch (error) {
                console.error("‚ùå Erro ao gerar resposta:", error);
                
                const errorMessage = error instanceof Error ? error.message : "Erro desconhecido";
                res.status(500).json({
                    success: false,
                    error: errorMessage
                });
            }
        }

    } catch (error) {
        console.error("‚ùå Erro no agentController:", error);
        
        if (!res.headersSent) {
            res.status(500).json({
                error: error instanceof Error ? error.message : "Erro interno do servidor"
            });
        }
    }
};
