/**
 * @fileoverview 
 * este arquivo √© o mais complexo do sistema, possui varias funcionalidades.
 * 1 - Sele√ß√£o e execu√ß√£o de ferramentas
 * 2- gera√ß√£o de r4esposta final.
 */

import { traceable } from "langsmith/traceable";
import { SystemMessage, HumanMessage, AIMessage } from "@langchain/core/messages";
import { advancedModel, balancedModel, fastModel } from "../../config";
import { storeChatMessage, retrieverSessionHistory } from "../../memory";
import { specificQueryTool, aggregateTool, hybridSearchTool, calculatorTool } from "../../tools/history/tools";



// essa fun√ß√£o gera a resposta da pergunta
export const generateResponseOpenAI = traceable(
    async function OpenAiChatCompleiton(
        messages: any, // historico de mensagem
        modelType: "advanced" | "balanced" | "fast" = "advanced", // modelos pre definidos (com a inten√ß√£o de diminuir a lat√™ncia)
        onChunk?: (chunk: string) => void  // streaming
    ): Promise<string> {
        try {

            /**
             * Indentifica o papel da mensagem
             * Converte as mensagens em formato langchain
             * Qualquer coisa fora do padr√£o √© mensagen di tipo HumanMessage, para garantir que nada quebre
             */
            const langchainMessages = messages.map((msg: any) => {
                if (msg.role === "system") return new SystemMessage(msg.content);
                if (msg.role === "user") return new HumanMessage(msg.content);
                if (msg.role === "assistant") return new AIMessage(msg.content);
                return new HumanMessage(msg.content); 
            });

            // define o modelo
            let selectedModel;
            if (modelType === "advanced") {
                selectedModel = advancedModel;
            } else if (modelType === "balanced") {
                selectedModel = balancedModel;
            } else {
                selectedModel = fastModel;
            }

            // caso seja o streaming esteja ativado, vai fazer o streaming
            if (onChunk) {
                const stream = await selectedModel.stream(langchainMessages);
                let fullResponse = "";
                
                for await (const chunk of stream) {
                    const content = String(chunk.content || "");
                    
                    if (content) {
                        onChunk(content);
                    }
                    
                    fullResponse += content;  
                }

                return fullResponse;
            } 
            else {
                // invoka a resposta do llm
                const response = await selectedModel.invoke(langchainMessages);
                return String(response.content);
            }

        } catch (error) {
            console.error("Error in OpenAiChatCompletion:", error);
            throw error;
        }
    },
    {
        name: "Generate Responde OpenAI",
        run_type: "llm",
        metadata: {
            provider: "OpenAI"
        }
    }
) as (messages: any, modelType?: "advanced" | "balanced" | "fast", onChunk?: (chunk: string) => void) => Promise<string>;


// essa fun√ß√£o √© um agente que pega o input do usu√°rio e com base nele determina qual a tool mais adequada.
export const runToolSelectorAgent = traceable(
    async function toolSelector(
        userInput: any,  // input do usuario
        sessionHistory: any[] = [] // historico da conversa
    ): Promise<{ tool: string; input: any }> {

        // prompt de instru√ß√£o do sistema.
        const systemPrompt = `
            Voc√™ √© um roteador de tarefas inteligente. Analise a INTEN√á√ÉO da pergunta, n√£o apenas as palavras exatas.

            ### Ferramentas Dispon√≠veis

                1. **specific_query_tool**: Busca informa√ß√µes espec√≠ficas sobre UMA entidade.
        
                    **Quando usar:**
                    - Pergunta menciona nome espec√≠fico de empresa, representante, organiza√ß√£o, etc.
                    - Usu√°rio quer saber sobre UM item espec√≠fico
                    - Funciona para QUALQUER propriedade: documento, plano, tipo, revenue, etc.
        
                    **Exemplos (n√£o limitado a estes):**
                        - "Qual o documento da iFood?"
                        - "Me fale o plano da SEM PARAR"
                        - "Qual o tipo da CREDIFY?"
                        - "Qual a organiza√ß√£o do SEGUNDO CART√ìRIO?"
                        - "Qual o revenue da iFood?"
        
                    **Varia√ß√µes aceitas:**
                        - "iFood tem qual documento?" ‚Üí ‚úÖ Mesma inten√ß√£o
                        - "Me mostre o plano da SEM PARAR" ‚Üí ‚úÖ Mesma inten√ß√£o
        
                    **Retorno:**
                    {"tool": "specific_query_tool", "input": {"query": "...", "filters": {}}}

                2. **aggregate_tool**: Agrega dados por QUALQUER campo.
        
                    **Quando usar:**
                        - Pergunta pede compara√ß√£o, ranking ou total de M√öLTIPLOS itens
                        - Usu√°rio quer ver dados agrupados
                        - Funciona para: representative, company, organization, revenue, plan, company_type, etc.
        
                    **Exemplos (n√£o limitado a estes):**
                        - "Desempenho por representante" ‚Üí groupBy: "representative"
                        - "Desempenho por empresa" ‚Üí groupBy: "company"
                        - "Agregue por organiza√ß√£o" ‚Üí groupBy: "organization"
                        - "Total por revenue" ‚Üí groupBy: "revenue"
                        - "Agrupe por plano" ‚Üí groupBy: "plan"
                        - "Empresas por tipo" ‚Üí groupBy: "company_type"

                        **Varia√ß√µes aceitas:**
                        - "Mostre cada representante" ‚Üí ‚úÖ groupBy: "representative"
                        - "Ranking de vendedores" ‚Üí ‚úÖ groupBy: "representative"
                        - "Compare as empresas" ‚Üí ‚úÖ groupBy: "company"
        
                    **Retorno:**
                    {"tool": "aggregate_tool", "input": {"query": "...", "filters": {}, "groupBy": "representative"}}
        
                    **‚ö†Ô∏è IMPORTANTE:** Voc√™ DEVE especificar o campo "groupBy" no input!

                3. **hybrid_search_tool**: Busca h√≠brida (fallback).
        
                    **Quando usar:**
                    - Pergunta √© amb√≠gua, complexa ou n√£o se encaixa claramente nas outras tools
                    - Voc√™ n√£o tem certeza qual tool usar
        
                    **Exemplos:**
                    - "Me explique como funciona..."
                    - "An√°lise detalhada de..."
                    - "Me fale sobre esses dados"
        
                    **Retorno:**
                    {"tool": "hybrid_search_tool", "input": {"query": "...", "filters": {}}}

                4. **none**: APENAS para cumprimentos e agradecimentos.
        
                    **Quando usar:**
                    - "oi", "ol√°", "bom dia"
                    - "obrigado", "valeu", "at√© logo"
        
                    **Retorno:**
                    {"tool": "none", "input": "..."}

            ### ‚ö†Ô∏è REGRAS CR√çTICAS:
                1. **Analise a INTEN√á√ÉO**, n√£o as palavras exatas
                2. **Os exemplos s√£o ilustrativos**, n√£o limitantes
                3. **Para agrega√ß√£o, SEMPRE especifique "groupBy"**
                4. **SE VOC√ä N√ÉO TEM CERTEZA** qual tool usar, escolha **hybrid_search_tool**
                5. **Formato JSON:** Retorne APENAS o JSON da ferramenta

            ### Exemplos Completos

            **Exemplo 1: Espec√≠fica**
                Hist√≥rico: []
                Usu√°rio: "Qual o documento da iFood?"
                Retorno:
                {"tool": "specific_query_tool", "input": {"query": "documento da iFood", "filters": {}}}

            **Exemplo 2: Agrega√ß√£o por Representante**
                Hist√≥rico: []
                Usu√°rio: "desempenho por representante"
                Retorno:
                {"tool": "aggregate_tool", "input": {"query": "desempenho de todos os representantes", "filters": {}, "groupBy": "representative"}}

            **Exemplo 3: Agrega√ß√£o por Plano**
                Hist√≥rico: []
                Usu√°rio: "agrupe por plano"
                Retorno:
                {"tool": "aggregate_tool", "input": {"query": "dados agrupados por plano", "filters": {}, "groupBy": "plan"}}

            **Exemplo 4: Agrega√ß√£o por Tipo de Empresa**
                Hist√≥rico: []
                Usu√°rio: "compare empresas master e unique"
                Retorno:
                {"tool": "aggregate_tool", "input": {"query": "compara√ß√£o entre tipos de empresa", "filters": {}, "groupBy": "company_type"}}

            **Exemplo 5: Amb√≠gua (Fallback)**
                Hist√≥rico: []
                Usu√°rio: "me explique como funciona"
                Retorno:
                {"tool": "hybrid_search_tool", "input": {"query": "explica√ß√£o sobre funcionamento", "filters": {}}}

            **Exemplo 6: Cumprimento**
                Hist√≥rico: [ ... ]
                Usu√°rio: "muito obrigado"
                Retorno:
                {"tool": "none", "input": "muito obrigado"}

    `.trim();

        // monta o hist√≥rico completo da conversa que sera enviada ao sistema.
        const messages = [
            { role: "system", content: systemPrompt },
            ...sessionHistory,
            { role: "user", content: userInput }
        ]

        try {
            // envia as mensagens para o llm e retorna a resposta
            const response = await generateResponseOpenAI(messages, "balanced");
            let toolCall;


            try {
                // converte a resposta para json
                toolCall = JSON.parse(response);
            } catch (parseError) {
                console.warn("‚ö†Ô∏è Erro ao parsear JSON. Usando fallback...");
                // caso haja alguma falha utiliza a ferramenta hybrid (generica)
                return { 
                    tool: "hybrid_search_tool", 
                    input: { query: userInput, filters: {} } 
                };
            }

            // ferramentas validas
            const validTools = [
                "specific_query_tool",
                "aggregate_tool",
                "hybrid_search_tool",
                "none"
            ];
            
            if (!toolCall || !toolCall.tool || !validTools.includes(toolCall.tool)) {
                console.warn("‚ö†Ô∏è Tool inv√°lida. Usando fallback.");
                return { 
                    tool: "hybrid_search_tool", 
                    input: { query: userInput, filters: {} } 
                };
            }

            if (!toolCall.input) {
                toolCall.input = { query: userInput, filters: {} };
            }

            
            if (toolCall.tool === "aggregate_tool" && !toolCall.input.groupBy) {
                toolCall.input.groupBy = "company";
            }

            console.log("‚úÖ Tool selecionada:", toolCall.tool);
            return {
                tool: toolCall.tool,
                input: toolCall.input
            };

        } catch (error) {
            console.error("‚ùå Erro no toolSelector:", error);
            return { 
                tool: "hybrid_search_tool", 
                input: { query: userInput, filters: {} } 
            };
        }

    },
    {
        name: "Tool Selector",
        run_type: "chain",
        metadata: {
            purpose: "Route user query to appropriate tool",
            model: "gpt-4o"
        }
    }
) as (userInput: any, sessionHistory?: any[]) => Promise<{ tool: string; input: any }>;

const getLlmResponse = traceable(
    async function getLlmResponse(
        messages: any, 
        systemMessageContent: any,
        modelType: "advanced" | "balanced" | "fast" = "advanced",
        onChunk?: (chunk: string) => void  
    ): Promise<string> {
        const fullMessages = [
            { role: "system", content: systemMessageContent },
            ...messages
        ];

        
        const response = await generateResponseOpenAI(fullMessages, modelType, onChunk);
        return response;
    },
    {
        name: "Get LLM Response",
        run_type: "chain",
        metadata: {
            purpose: "Generate final response with system prompt"
        }
    }
) as (messages: any, systemMessageContent: any, modelType?: "advanced" | "balanced" | "fast", onChunk?: (chunk: string) => void) => Promise<string>;


/**
 * Fun√ß√£o principal que orquestra todo o processo. Ela √© respons√°vel por:
 */
export const generateResponse = traceable(
    async function generateResponse(
        sessionId: any, // sess√£o do chat do usuario
        userInput: any, // pergunta do usuario
        onChunk?: (chunk: string) => void  // streaming
    ): Promise<string> {
        
        // armazena a pergunta do usu√°iro no hist√≥rico de se√ß√£o.
        await storeChatMessage(sessionId, "user", userInput);

        // recupera todo o hist√≥rico da conversa, para entender o contexto
        const sessionHistory: any[] = await retrieverSessionHistory(sessionId);

    
        const llmInput = [...sessionHistory];

        // retorno da fun√ß√£o que seleciona a ferramenta
        const { tool, input: toolInput } = await runToolSelectorAgent(userInput, sessionHistory);
        console.log("üîß Tool selecionada:", tool);

        let response;

        
        if (tool === "specific_query_tool") {
            console.log("üîç Executando specific_query_tool...");
            
            const finalFilters = { "month": sessionId };
            const finalToolInput = { 
                query: toolInput.query || userInput, 
                filters: finalFilters 
            };
            
            const contextResults = await specificQueryTool(finalToolInput);
            const context = contextResults
                .map((doc:any) => doc.document?.pageContent || JSON.stringify(doc))
                .join('\n---\n');
            
            const systemMessageContent = `
Voc√™ √© um analista financeiro experiente. Responda usando o contexto fornecido.

**FORMATA√á√ÉO MONET√ÅRIA:**
- Os valores J√Å EST√ÉO EM REAIS (n√£o precisa converter)
- Campos como "totalValueInReais", "totalValueWithDiscountInReais" j√° est√£o prontos
- Use o padr√£o brasileiro: ponto (.) para separador de milhares, v√≠rgula (,) para decimais
- Exemplo: 11893.2337 ‚Üí R$ 11.893,2337
- Exemplo: 316852.5000 ‚Üí R$ 316.852,5000
- SEMPRE mostre exatamente 4 casas decimais ap√≥s a v√≠rgula
- NUNCA use v√≠rgula para separador de milhares

### üß© POL√çTICA DE FORMATA√á√ÉO DE RESPOSTAS (OBRIGAT√ìRIA)

Todas as respostas devem ser formatadas em **Markdown**, SEM EXCE√á√ÉO.

**Regras de Formata√ß√£o:**
1. **T√≠tulos:** Use \`##\` para t√≠tulos principais e \`###\` para subt√≠tulos.
2. **Negrito:** Use \`**texto**\` para destacar partes importantes.
3. **Tabelas:** Sempre que houver compara√ß√£o, agrega√ß√£o ou m√∫ltiplos itens (empresas, representantes, meses, etc.), use tabelas Markdown no formato:

   | Campo | Valor |
   |--------|--------|
   | Exemplo | R$ 1.234,56 |

4. **C√≥digo Inline:** Use crases \`texto\` para IDs, nomes t√©cnicos, ou campos JSON.
5. **Separadores:** Use \`---\` para separar blocos de informa√ß√£o.
6. **Listas:** Use listas numeradas ou com marcadores para explicar passos, m√©tricas ou observa√ß√µes.
7. **Emojis (opcional):** Pode usar √≠cones (üìä, üí∞, ‚öôÔ∏è) para dar contexto visual.
8. **Proibido:** N√£o retornar texto puro sem Markdown.
- Seja conciso mas informativo


Contexto:
${context}`.trim();
            
            
            response = await getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        
        
        else if (tool === "aggregate_tool") {
            console.log("üìä Executando aggregate_tool...");
            
            const finalFilters = { "month": sessionId };
            const finalToolInput = { 
                query: toolInput.query || userInput, 
                filters: finalFilters,
                groupBy: toolInput.groupBy || "company"
            };
            
            const contextResults = await aggregateTool(finalToolInput);
            const contextData = JSON.parse(contextResults[0].document.pageContent);
            const context = JSON.stringify(contextData, null, 2);
            
            const systemMessageContent = `
Voc√™ √© um analista financeiro experiente. Os dados fornecidos J√Å EST√ÉO AGREGADOS.
N√ÉO precisa somar ou agrupar novamente! Apenas formate e analise.

**FORMATA√á√ÉO MONET√ÅRIA:**
- Os valores J√Å EST√ÉO EM REAIS (n√£o precisa converter)
- Campos como "totalValueInReais", "totalValueWithDiscountInReais" j√° est√£o prontos
- Use o padr√£o brasileiro: ponto (.) para separador de milhares, v√≠rgula (,) para decimais
- Exemplo: 11893.2337 ‚Üí R$ 11.893,2337
- Exemplo: 316852.5000 ‚Üí R$ 316.852,5000
- SEMPRE mostre exatamente 4 casas decimais ap√≥s a v√≠rgula
- NUNCA use v√≠rgula para separador de milhares

### üß© POL√çTICA DE FORMATA√á√ÉO DE RESPOSTAS (OBRIGAT√ìRIA)

Todas as respostas devem ser formatadas em **Markdown**, SEM EXCE√á√ÉO.

**Regras de Formata√ß√£o:**
1. **T√≠tulos:** Use \`##\` para t√≠tulos principais e \`###\` para subt√≠tulos.
2. **Negrito:** Use \`**texto**\` para destacar partes importantes.
3. **Tabelas:** Sempre que houver compara√ß√£o, agrega√ß√£o ou m√∫ltiplos itens (empresas, representantes, meses, etc.), use tabelas Markdown no formato:

   | Campo | Valor |
   |--------|--------|
   | Exemplo | R$ 1.234,56 |

4. **C√≥digo Inline:** Use crases \`texto\` para IDs, nomes t√©cnicos, ou campos JSON.
5. **Separadores:** Use \`---\` para separar blocos de informa√ß√£o.
6. **Listas:** Use listas numeradas ou com marcadores para explicar passos, m√©tricas ou observa√ß√µes.
7. **Emojis (opcional):** Pode usar √≠cones (üìä, üí∞, ‚öôÔ∏è) para dar contexto visual.
8. **Proibido:** N√£o retornar texto puro sem Markdown.
- Seja conciso mas informativo

Contexto (j√° agregado por ${toolInput.groupBy}):
${context}`.trim();
            
            
            response = await getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        
        
        else if (tool === "hybrid_search_tool") {
            console.log("üîÄ Executando hybrid_search_tool...");
            
            const finalFilters = { "month": sessionId };
            const finalToolInput = { 
                query: toolInput.query || userInput, 
                filters: finalFilters 
            };
            
            const contextResults = await hybridSearchTool(finalToolInput);
            const context = contextResults
                .map((doc:any) => doc.document?.pageContent || JSON.stringify(doc))
                .join('\n---\n');
            
            const systemMessageContent = `
Voc√™ √© um analista financeiro experiente. Fa√ßa uma an√°lise abrangente e detalhada.

**FORMATA√á√ÉO MONET√ÅRIA:**
- Os valores J√Å EST√ÉO EM REAIS (n√£o precisa converter)
- Campos como "totalValueInReais", "totalValueWithDiscountInReais" j√° est√£o prontos
- Use o padr√£o brasileiro: ponto (.) para separador de milhares, v√≠rgula (,) para decimais
- Exemplo: 11893.2337 ‚Üí R$ 11.893,2337
- Exemplo: 316852.5000 ‚Üí R$ 316.852,5000
- SEMPRE mostre exatamente 4 casas decimais ap√≥s a v√≠rgula
- NUNCA use v√≠rgula para separador de milhares

### üß© POL√çTICA DE FORMATA√á√ÉO DE RESPOSTAS (OBRIGAT√ìRIA)

Todas as respostas devem ser formatadas em **Markdown**, SEM EXCE√á√ÉO.

**Regras de Formata√ß√£o:**
1. **T√≠tulos:** Use \`##\` para t√≠tulos principais e \`###\` para subt√≠tulos.
2. **Negrito:** Use \`**texto**\` para destacar partes importantes.
3. **Tabelas:** Sempre que houver compara√ß√£o, agrega√ß√£o ou m√∫ltiplos itens (empresas, representantes, meses, etc.), use tabelas Markdown no formato:

   | Campo | Valor |
   |--------|--------|
   | Exemplo | R$ 1.234,56 |

4. **C√≥digo Inline:** Use crases \`texto\` para IDs, nomes t√©cnicos, ou campos JSON.
5. **Separadores:** Use \`---\` para separar blocos de informa√ß√£o.
6. **Listas:** Use listas numeradas ou com marcadores para explicar passos, m√©tricas ou observa√ß√µes.
7. **Emojis (opcional):** Pode usar √≠cones (üìä, üí∞, ‚öôÔ∏è) para dar contexto visual.
8. **Proibido:** N√£o retornar texto puro sem Markdown.
- Seja direto mas completo

Contexto:
${context}`.trim();
            
            
            response = await getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }
        
        
        else if (tool === "calculator_tool") {
            console.log("üßÆ Executando calculator_tool...");
            response = calculatorTool(toolInput);
            
            
            if (onChunk) {
                onChunk(response);
            }
        }
        
        
        else {
            console.log("üí¨ Nenhuma tool necess√°ria (cumprimento)");
            
            const systemMessageContent = `
                Voc√™ √© um assistente prestativo. Seja cordial.
                Use Markdown se necess√°rio.
            `.trim();
            
            
            response = await getLlmResponse(llmInput, systemMessageContent, "fast", onChunk);
        }

        await storeChatMessage(sessionId, "system", response);
        return response;

    },
    {
        name: "Generate Response - novo",
        run_type: "chain",
        metadata: {
            purpose: "Main orchestration with optimized model selection and streaming"
        }
    }
) as (sessionId: any, userInput: any, onChunk?: (chunk: string) => void) => Promise<string>;
